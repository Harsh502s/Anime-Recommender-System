{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from ast import literal_eval as le\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings as w\n",
    "\n",
    "w.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "stopwords_nltk = stopwords.words(\"english\")\n",
    "stopwords_spacy = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stopwords = set(stopwords_nltk + list(stopwords_spacy))\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"anime_data.csv\")\n",
    "df.reset_index(inplace=True)\n",
    "url_df = pd.read_csv(\"anime_url.csv\")\n",
    "url_df.reset_index(inplace=True)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df = url_df.merge(df, on='index',how='left')\n",
    "df.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.anime_producer = df.anime_producer.replace(\"['NA']\", df.anime_producer.mode()[0])\n",
    "df.anime_studio = df.anime_studio.replace(np.nan, df.anime_studio.mode()[0])\n",
    "df.anime_mal_score = pd.to_numeric(df.anime_mal_score, errors=\"coerce\")\n",
    "df.anime_mal_score = df.anime_mal_score.replace(np.nan, df.anime_mal_score.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True,keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.anime_genres = df.anime_genres.apply(le)\n",
    "df.anime_producer = df.anime_producer.apply(le)\n",
    "df.anime_genres = df.anime_genres.apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "df.anime_studio = df.anime_studio.apply(lambda x: x.replace(\" \", \"\"))\n",
    "df.anime_studio = df.anime_studio.apply(lambda x: x.split())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anime_overview'] =  df['anime_overview'].apply(lambda x: x.split(r\"[Written by MAL Rewrite]\")[0])\n",
    "\n",
    "# Taking Only Words\n",
    "df['anime_overview'] = df['anime_overview'].apply(lambda x: \" \".join(re.findall(r'[a-zA-Z]+', x)).lower())\n",
    "\n",
    "# Removing all s and t from the overview which are not in the form of words\n",
    "\n",
    "df['anime_overview'] = df['anime_overview'].apply(lambda x: re.sub(r'\\bs\\b|\\bt\\b','',x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the index column and resetting the index to new values\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the column names\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"index\": \"anime_id\",\n",
    "        \"anime_urls\": \"urls\",\n",
    "        \"anime_overview\": \"overview\",\n",
    "        \"anime_genres\": \"genres\",\n",
    "        \"anime_producer\": \"producer\",\n",
    "        \"anime_studio\": \"studio\",\n",
    "        \"anime_mal_score\": \"score\",\n",
    "        \"anime_poster\": \"poster\",\n",
    "        \"anime_title\": \"title\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making tags as a combination of overview, genres and studio\n",
    "df.overview = df.overview.astype(str)\n",
    "df.overview = df.overview.apply(lambda x: x.split())\n",
    "\n",
    "df['tags'] = df['overview'] + df['genres'] + df['studio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['tags'].apply(lambda x:[i.lower() for i in x])\n",
    "df['tags'] = df['tags'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing the tags\n",
    "\n",
    "def stemmer(text):\n",
    "    doc = nlp(text)\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ not in stopwords]\n",
    "    return ' '.join(doc)\n",
    "\n",
    "df['tags'] = df['tags'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7193, 10000)\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer to convert tags into matrix\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',max_features=10000,ngram_range=(1,3),norm='l2')\n",
    "vector = vectorizer.fit_transform(df['tags']).toarray()\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.00923732, 0.        , ..., 0.00848941, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity\n",
    "\n",
    "similarity = cosine_similarity(vector)\n",
    "similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naruto: Shippuden\n",
      "Naruto: Shippuuden Movie 4 - The Lost Tower\n",
      "Boruto: Naruto Next Generations\n",
      "Naruto: Shippuuden Movie 6: Road to Ninja\n",
      "Boruto: Naruto the Movie\n",
      "Naruto Shippuuden Movie 3: Inheritors of Will of Fire\n",
      "Naruto: Shippuuden Movie 5 - Blood Prison\n",
      "Naruto: Shippuden the Movie 2 -Bonds-\n",
      "Naruto OVA7: Chunin Exam on Fire! and Naruto vs. Konohamaru!\n",
      "Naruto OVA2: The Lost Story - Mission: Protect the Waterfall Village\n"
     ]
    }
   ],
   "source": [
    "def recommend(anime):\n",
    "    index = df[df['title'] == anime].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x: x[1])[1:11]\n",
    "    for i in distances:\n",
    "        print(df.iloc[i[0]].title)\n",
    "        pass\n",
    "    \n",
    "recommend('Naruto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"rec_data.csv\", index=False)\n",
    "df.to_csv(r\"D:\\Github\\Anime-Recommender\\rec_data.csv\", index=False)\n",
    "pickle.dump(similarity, open(r\"D:\\Github\\Anime-Recommender\\similarity.pkl\", \"wb\"))\n",
    "pickle.dump(similarity, open(r\"similarity.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
