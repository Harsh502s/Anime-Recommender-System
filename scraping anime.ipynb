{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Anime from Zoro.to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "\n",
    "import warnings as w\n",
    "\n",
    "w.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "no_of_page = int(\n",
    "    BeautifulSoup(requests.get(\"https://aniwatch.to/az-list\").content, \"lxml\")\n",
    "    .find(\"nav\", attrs={\"aria-label\": \"Page navigation\"})\n",
    "    .find_all(\"li\")[-1]\n",
    "    .find(\"a\")[\"href\"]\n",
    "    .split(\"=\")[1]\n",
    ")\n",
    "landing_page_url = \"https://aniwatch.to/az-list\"\n",
    "page_urls = [\n",
    "    f\"{landing_page_url}/page={i}\" if i != 1 else landing_page_url\n",
    "    for i in range(1, no_of_page + 1)\n",
    "]\n",
    "\n",
    "# Scraping the data from all the pages\n",
    "\n",
    "anime_urls = []\n",
    "\n",
    "for url in page_urls:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    # Getting the url for the anime page\n",
    "\n",
    "    for anime in soup.find_all(\"div\", class_=\"film-poster\"):\n",
    "        anime = anime.find(\"a\")[\"href\"]\n",
    "        page = \"https://aniwatch.to\" + anime\n",
    "        anime_urls.append(page)\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the data from all the anime pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(url):\n",
    "    soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "\n",
    "    anime_poster = soup.find(\"div\", class_=\"film-poster\").find(\"img\")[\"src\"]\n",
    "\n",
    "    # Getting the name of the anime\n",
    "\n",
    "    anime_title = soup.find(\"h2\", class_=\"film-name dynamic-name\").text\n",
    "\n",
    "    # Getting the overview of the anime\n",
    "\n",
    "    anime_overview = anime_overview = (\n",
    "        soup.find(\"div\", class_=\"item item-title w-hide\")\n",
    "        .find(\"div\", class_=\"text\")\n",
    "        .text\n",
    "    )\n",
    "\n",
    "    # Creating an object of the div containing all the details of the anime\n",
    "\n",
    "    soup = soup.find(\"div\", class_=\"anisc-info\")\n",
    "\n",
    "    # Extract MAL Score\n",
    "    mal_score_element = soup.find(\"span\", {\"class\": \"item-head\"}, text=\"MAL Score:\")\n",
    "    anime_mal_score = (\n",
    "        mal_score_element.find_next_sibling(\"span\", {\"class\": \"name\"}).text.strip()\n",
    "        if mal_score_element\n",
    "        else \"NA\"\n",
    "    )\n",
    "\n",
    "    # Extract Studios\n",
    "    studios_element = soup.find(\"span\", {\"class\": \"item-head\"}, text=\"Studios:\")\n",
    "    anime_studio = (\n",
    "        studios_element.find_next(\"a\", {\"class\": \"name\"}).text.strip()\n",
    "        if studios_element\n",
    "        else \"NA\"\n",
    "    )\n",
    "\n",
    "    # Extract Producers\n",
    "    producers_element = soup.find(\"span\", {\"class\": \"item-head\"}, text=\"Producers:\")\n",
    "    anime_producer = (\n",
    "        [\n",
    "            producer.text.strip()\n",
    "            for producer in producers_element.find_next_siblings(\"a\")\n",
    "        ]\n",
    "        if producers_element\n",
    "        else [\"NA\"]\n",
    "    )\n",
    "\n",
    "    # Extract Genres\n",
    "    genres_element = soup.find(\"span\", {\"class\": \"item-head\"}, text=\"Genres:\")\n",
    "    anime_genres = (\n",
    "        [genre.text.strip() for genre in genres_element.find_next_siblings(\"a\")]\n",
    "        if genres_element\n",
    "        else [\"NA\"]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        anime_poster,\n",
    "        anime_title,\n",
    "        anime_overview,\n",
    "        anime_mal_score,\n",
    "        anime_studio,\n",
    "        anime_producer,\n",
    "        anime_genres,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_df_parallel(df, num_threads=4):\n",
    "    anime_urls = df[\"anime_urls\"].tolist()\n",
    "\n",
    "    anime_poster_list = []\n",
    "    anime_title_list = []\n",
    "    anime_overview_list = []\n",
    "    anime_mal_score_list = []\n",
    "    anime_studio_list = []\n",
    "    anime_producer_list = []\n",
    "    anime_genres_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        results = executor.map(process_url, anime_urls)\n",
    "\n",
    "        for result in results:\n",
    "            anime_poster_list.append(result[0])\n",
    "            anime_title_list.append(result[1])\n",
    "            anime_overview_list.append(result[2])\n",
    "            anime_mal_score_list.append(result[3])\n",
    "            anime_studio_list.append(result[4])\n",
    "            anime_producer_list.append(result[5])\n",
    "            anime_genres_list.append(result[6])\n",
    "\n",
    "    anime_dict = {\n",
    "        \"anime_poster\": anime_poster_list,\n",
    "        \"anime_title\": anime_title_list,\n",
    "        \"anime_overview\": anime_overview_list,\n",
    "        \"anime_mal_score\": anime_mal_score_list,\n",
    "        \"anime_studio\": anime_studio_list,\n",
    "        \"anime_producer\": anime_producer_list,\n",
    "        \"anime_genres\": anime_genres_list,\n",
    "    }\n",
    "\n",
    "    anime_df = pd.DataFrame(anime_dict)\n",
    "    return anime_df\n",
    "\n",
    "\n",
    "anime_df = create_df_parallel(df)\n",
    "anime_df.head()\n",
    "anime_df.to_csv(\"anime_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
